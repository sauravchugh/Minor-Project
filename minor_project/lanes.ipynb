{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now our next step is edge detection. In order to effectively detect an edge we need \n",
    "to follow the following step:\n",
    "    1. convert into grey image. Colourful image has the combination of 3 colors    red,green,blue\n",
    "    called 3 channel on the other hand grey image is one channel containing ony one color with\n",
    "    varying intensity from 0-255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "src data type = 17 is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a7194b33aa7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_image1.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# 0 for grey image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlane_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlane_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'result'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#cv2.waitKey(0)# for indefinite wait unless key stroke,for saving you can use imwrite()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: src data type = 17 is not supported"
     ]
    }
   ],
   "source": [
    "image=cv2.imread('test_image1.jpg',0)# 0 for grey image\n",
    "lane_image=np.copy(image)\n",
    "gray=\n",
    "#gray=cv2.cvtColor(lane_image,cv2.COLOR_RGB2GRAY)\n",
    "cv2.imshow('result',gray)\n",
    "#cv2.waitKey(0)# for indefinite wait unless key stroke,for saving you can use imwrite()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP2 :Nise reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gray' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-eac30228dfbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mblur\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'blurred'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#cv2.waitKey(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gray' is not defined"
     ]
    }
   ],
   "source": [
    "blur=cv2.GaussianBlur(gray,(5,5),0)\n",
    "cv2.imshow('blurred',blur)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcess:\n",
    "    def image_preprocessing(self,path_of_image):\n",
    "        image=cv2.imread(path_of_image)\n",
    "        lane_image=np.copy(image)\n",
    "        gray=cv2.cvtColor(lane_image,cv2.COLOR_RGB2GRAY)\n",
    "        blur=cv2.GaussianBlur(gray,(5,5),0)\n",
    "        return blur\n",
    "    def merge_image(self,lane_image,line_image):\n",
    "        combo_image=cv2.addWeighted(lane_image,0.8,line_image,1,1)\n",
    "        return combo_image\n",
    "\n",
    "    #def collect_frames(self,vedio):\n",
    "    #    cap=cv2.VideoCapture(\"solidWhiteRight.mp4\")\n",
    "     #   while(cap.isOpened()):\n",
    "       #     _ ,frame=cap.read()\n",
    "        #    canny_image=canny(frame)\n",
    "         #   cropped_image=region_of_interest(canny_image)\n",
    "          #  lines=cv2.HoughLinesP(cropped_image,2,np.pi/180,100,np.array([]),minLineLength=40,maxLineGap=5)# return 3d array\n",
    "          #  averaged_lines=average_slope_intercept(lane_image,lines)\n",
    "            #line_image=display_lines(lane_image,averaged_lines)\n",
    "           # combo_image=cv2.addWeighted(lane_image,0.8,line_image,1,1)\n",
    "           # cv2.imshow('combined image',combo_image)\n",
    "           # if cv2.waitKey(1) & 0XFF==ord('q'):\n",
    "           # break\n",
    "        #cap.release()\n",
    "        #cv2.destroyAllWindows()\n",
    "     \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CannyClass:\n",
    "    def canny(self,image):\n",
    "      #gray=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "      #blur=cv2.GaussianBlur(gray,(5,5),0)\n",
    "      canny=cv2.Canny(image,50,150)\n",
    "      return canny\n",
    "    \n",
    "    def region_of_interest(self,image):\n",
    "        height=image.shape[0]\n",
    "        polygon=np.array([[(300,height),(1000,height),(580,250)]])\n",
    "        mask=np.zeros_like(image)\n",
    "        cv2.fillPoly(mask,polygon,255)\n",
    "        masked_image=cv2.bitwise_and(image,mask)\n",
    "        return masked_image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HoughClass:\n",
    "    def display_lines(self,image,lines):\n",
    "        line_image=np.zeros_like(image)\n",
    "        if lines is not None:\n",
    "            for line in lines:\n",
    "                x1,y1,x2,y2=line.reshape(4)\n",
    "                cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),10)# third argu is for color of line only,last one is thickness of line\n",
    "        return line_image  \n",
    "    \n",
    "    def make_coordinates(self,image,line_parameters):\n",
    "        slope,intercept=line_parameters\n",
    "        y1=image.shape[0]#(y coordiante,x coo,number of chhanelded)\n",
    "        y2=int(y1*3/5)\n",
    "        x1=int((y1-intercept)/slope)\n",
    "        x2=int((y2-intercept)/slope)\n",
    "        return np.array([x1,y1,x2,y2])\n",
    "    \n",
    "    def average_slope_intercept(self,image,lines):\n",
    "        left_fit=[]\n",
    "        right_fit=[]\n",
    "        for line in lines:\n",
    "            x1,y1,x2,y2=line.reshape(4)\n",
    "            parameters=np.polyfit((x1,x2),(y1,y2),1)# it print slope and y intercept\n",
    "            slope=parameters[0]\n",
    "            intercept=parameters[1]\n",
    "            if slope<0:\n",
    "                left_fit.append((slope,intercept))\n",
    "            else:\n",
    "                right_fit.append((slope,intercept))\n",
    "        average_left_fit=np.average(left_fit,axis=0)\n",
    "        average_right_fit=np.average(right_fit,axis=0)\n",
    "        left_line=make_coordinates(image,average_left_fit)\n",
    "        right_line=make_coordinates(image,average_right_fit)\n",
    "        return np.array([left_line,right_line])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3 : Applying canny algo....working of this algo is shown in ppt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blur' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3488e4781a1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcanny\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCanny\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblur\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'c_200_250.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcanny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'canny'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcanny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#cv2.waitKey(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'blur' is not defined"
     ]
    }
   ],
   "source": [
    "canny=cv2.Canny(blur,200,250)\n",
    "cv2.imwrite('c_200_250.jpg',canny)\n",
    "cv2.imshow('canny',canny)\n",
    "#cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " So,now Let me cover this one process in a function, matplot also conatin function imshow()  and show it just use show(), so I am replacing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def canny(image):\n",
    "    #gray=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    #blur=cv2.GaussianBlur(gray,(5,5),0)\n",
    "   # canny=cv2.Canny(image,50,150)\n",
    "    #return canny\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def region_of_interest(image):\n",
    " #   height=image.shape[0]\n",
    "  #  polygon=np.array([[(300,height),(1000,height),(580,250)]])\n",
    "   # mask=np.zeros_like(image)\n",
    "    #cv2.fillPoly(mask,polygon,255)\n",
    "    #masked_image=cv2.bitwise_and(image,mask)\n",
    "    #return masked_image\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_lines(image,lines):\n",
    "    line_image=np.zeros_like(image)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1,y1,x2,y2=line.reshape(4)\n",
    "            cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),10)# third argu is for color of line only,last one is thickness of line\n",
    "    return line_image    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_coordinates(image,line_parameters):\n",
    "    slope,intercept=line_parameters\n",
    "    y1=image.shape[0]#(y coordiante,x coo,number of chhanelded)\n",
    "    y2=int(y1*3/5)\n",
    "    x1=int((y1-intercept)/slope)\n",
    "    x2=int((y2-intercept)/slope)\n",
    "    return np.array([x1,y1,x2,y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_slope_intercept(image,lines):\n",
    "    left_fit=[]\n",
    "    right_fit=[]\n",
    "    for line in lines:\n",
    "            x1,y1,x2,y2=line.reshape(4)\n",
    "            parameters=np.polyfit((x1,x2),(y1,y2),1)# it print slope and y intercept\n",
    "            slope=parameters[0]\n",
    "            intercept=parameters[1]\n",
    "            if slope<0:\n",
    "                left_fit.append((slope,intercept))\n",
    "            else:\n",
    "                right_fit.append((slope,intercept))\n",
    "    average_left_fit=np.average(left_fit,axis=0)\n",
    "    average_right_fit=np.average(right_fit,axis=0)\n",
    "    left_line=make_coordinates(image,average_left_fit)\n",
    "    right_line=make_coordinates(image,average_right_fit)\n",
    "    return np.array([left_line,right_line])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageProcess' object has no attribute 'imagepreprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-671f2b8e0fee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpath_of_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test_image1.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mobject_of_imageClass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImageProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlane_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_of_imageClass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimagepreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_of_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mobject_of_cannyClass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCannyClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ImageProcess' object has no attribute 'imagepreprocessing'"
     ]
    }
   ],
   "source": [
    "#image=cv2.imread('test_image1.jpg')\n",
    "#lane_image=np.copy(image)\n",
    "path_of_image='test_image1.jpg'\n",
    "object_of_imageClass=ImageProcess()\n",
    "lane_image=object_of_imageClass.imagepreprocessing(path_of_image)\n",
    "\n",
    "object_of_cannyClass=CannyClass()\n",
    "canny_image=object_of_cannyClass.canny(lane_image)\n",
    "#canny_image=canny(lane_image)\n",
    "cv2.imshow('result',canny_image)\n",
    "cv2.waitKey(0)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "cropped_image=object_of_cannyClass.region_of_interest(canny_image)\n",
    "plt.imshow(cropped_image)\n",
    "plt.show()\n",
    "cv2.imshow('result',cropped_image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now Hough transformation. this algo is used to find straght line ,more specifically it connects two or more points\n",
    ". it draw number of lines throgh each of points abd draw hough space (m vs b) or(p,angle ) in polar coordinate.\n",
    "and it draws line according to value of (m,b) or(p,angle) which has more intersection tha others points..refer ppt for \n",
    "more detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# houghLinesP(image,resolution parameter,size of bin, min threshold,placehold array,minlinelength,mxlinegap)  \n",
    "bin it is box in our hough trnasformation...  min threshold  it is min voting required for getting accepted so tht we can draw a line .....optimizing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "src data type = 17 is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7dd6a06e3926>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpath_of_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test_image1.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mobject_of_imageClass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mImageProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlane_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_of_imageClass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_of_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mobject_of_cannyClass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCannyClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-954c0c0e5054>\u001b[0m in \u001b[0;36mimage_preprocessing\u001b[0;34m(self, path_of_image)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_of_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mlane_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mgray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlane_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mblur\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mblur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: src data type = 17 is not supported"
     ]
    }
   ],
   "source": [
    "#image=cv2.imread('test_image1.jpg')\n",
    "#lane_image=np.copy(image)\n",
    "#canny_image=canny(lane_image)\n",
    "#cropped_image=region_of_interest(canny_image)\n",
    "path_of_image='test_image1.jpg'\n",
    "object_of_imageClass=ImageProcess()\n",
    "lane_image=object_of_imageClass.image_preprocessing(path_of_image)\n",
    "\n",
    "object_of_cannyClass=CannyClass()\n",
    "canny_image=object_of_cannyClass.canny(lane_image)\n",
    "cropped_image=object_of_cannyClass.region_of_interest(canny_image)\n",
    "object_of_houghClass=HoughClass()\n",
    "lines=cv2.HoughLinesP(cropped_image,2,np.pi/180,100,np.array([]),minLineLength=40,maxLineGap=5)# return 3d array\n",
    "averaged_lines=object_of_houghClass.average_slope_intercept(lane_image,lines)\n",
    "line_image=object_of_houghClass.display_lines(lane_image,averaged_lines)\n",
    "combo_image=object_of_imageClass.merge_image(lane_image,line_image)\n",
    "plt.imshow(line_image)\n",
    "plt.show()\n",
    "cv2.imshow('result',line_image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now our next step is to combine original image with image which having lane detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'canny' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ae4ae694f709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_image1.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlane_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcanny_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcanny\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlane_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcropped_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregion_of_interest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanny_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHoughLinesP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcropped_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mminLineLength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxLineGap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# return 3d array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'canny' is not defined"
     ]
    }
   ],
   "source": [
    "image=cv2.imread('test_image1.jpg')\n",
    "lane_image=np.copy(image)\n",
    "canny_image=canny(lane_image)\n",
    "cropped_image=region_of_interest(canny_image)\n",
    "lines=cv2.HoughLinesP(cropped_image,2,np.pi/180,100,np.array([]),minLineLength=40,maxLineGap=5)# return 3d array\n",
    "averaged_lines=average_slope_intercept(lane_image,lines)\n",
    "line_image=display_lines(lane_image,averaged_lines)\n",
    "combo_image=cv2.addWeighted(lane_image,0.8,line_image,1,1)# .8  and 1 are pixel parameter for intensity of two image\n",
    "\n",
    "plt.imshow(line_image)\n",
    "plt.show()\n",
    "cv2.imshow('combined image',combo_image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'canny' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-bac77158cf93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcanny_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcanny\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcropped_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregion_of_interest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanny_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHoughLinesP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcropped_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mminLineLength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxLineGap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# return 3d array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'canny' is not defined"
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture(\"solidWhiteRight.mp4\")\n",
    "while(cap.isOpened()):\n",
    "    _ ,frame=cap.read()\n",
    "    canny_image=canny(frame)\n",
    "    cropped_image=region_of_interest(canny_image)\n",
    "    lines=cv2.HoughLinesP(cropped_image,2,np.pi/180,100,np.array([]),minLineLength=40,maxLineGap=5)# return 3d array\n",
    "    averaged_lines=average_slope_intercept(lane_image,lines)\n",
    "    line_image=display_lines(lane_image,averaged_lines)\n",
    "    combo_image=cv2.addWeighted(lane_image,0.8,line_image,1,1)\n",
    "    cv2.imshow('combined image',combo_image)\n",
    "    if cv2.waitKey(1) & 0XFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
